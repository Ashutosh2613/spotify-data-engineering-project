{
	"metadata": {
		"kernelspec": {
			"name": "glue_pyspark",
			"display_name": "Glue PySpark",
			"language": "python"
		},
		"language_info": {
			"name": "Python_Glue_Session",
			"mimetype": "text/x-python",
			"codemirror_mode": {
				"name": "python",
				"version": 3
			},
			"pygments_lexer": "python3",
			"file_extension": ".py"
		}
	},
	"nbformat_minor": 4,
	"nbformat": 4,
	"cells": [
		{
			"cell_type": "code",
			"source": "%idle_timeout 2880\n%glue_version 4.0\n%worker_type G.1X\n%number_of_workers 5\n\nimport sys\nfrom awsglue.transforms import *\nfrom awsglue.utils import getResolvedOptions\nfrom pyspark.context import SparkContext\nfrom awsglue.context import GlueContext\nfrom awsglue.job import Job\nimport boto3\n  \nsc = SparkContext.getOrCreate()\nglueContext = GlueContext(sc)\nspark = glueContext.spark_session\njob = Job(glueContext)",
			"metadata": {
				"trusted": true,
				"editable": true
			},
			"execution_count": 5,
			"outputs": [
				{
					"name": "stderr",
					"text": "You are already connected to a glueetl session c7285399-dcf0-4d45-bf4b-693b5d7895ac.\n\nNo change will be made to the current session that is set as glueetl. The session configuration change will apply to newly created sessions.\n",
					"output_type": "stream"
				},
				{
					"name": "stdout",
					"text": "Current idle_timeout is None minutes.\nidle_timeout has been set to 2880 minutes.\n",
					"output_type": "stream"
				},
				{
					"name": "stderr",
					"text": "You are already connected to a glueetl session c7285399-dcf0-4d45-bf4b-693b5d7895ac.\n\nNo change will be made to the current session that is set as glueetl. The session configuration change will apply to newly created sessions.\n",
					"output_type": "stream"
				},
				{
					"name": "stdout",
					"text": "Setting Glue version to: 4.0\n",
					"output_type": "stream"
				},
				{
					"name": "stderr",
					"text": "You are already connected to a glueetl session c7285399-dcf0-4d45-bf4b-693b5d7895ac.\n\nNo change will be made to the current session that is set as glueetl. The session configuration change will apply to newly created sessions.\n",
					"output_type": "stream"
				},
				{
					"name": "stdout",
					"text": "Previous worker type: None\nSetting new worker type to: G.1X\n",
					"output_type": "stream"
				},
				{
					"name": "stderr",
					"text": "You are already connected to a glueetl session c7285399-dcf0-4d45-bf4b-693b5d7895ac.\n\nNo change will be made to the current session that is set as glueetl. The session configuration change will apply to newly created sessions.\n",
					"output_type": "stream"
				},
				{
					"name": "stdout",
					"text": "Previous number of workers: None\nSetting new number of workers to: 5\n\n",
					"output_type": "stream"
				}
			]
		},
		{
			"cell_type": "code",
			"source": "from pyspark.sql.functions import *\nfrom datetime import datetime\nfrom awsglue.dynamicframe import DynamicFrame",
			"metadata": {
				"trusted": true,
				"tags": []
			},
			"execution_count": 2,
			"outputs": [
				{
					"name": "stdout",
					"text": "\n",
					"output_type": "stream"
				}
			]
		},
		{
			"cell_type": "code",
			"source": "s3_path = \"s3://spotify-bucket-etl-ashutosh/raw-data/to-be-processed-data/\"\nsource_dyf = glueContext.create_dynamic_frame_from_options(\n    connection_type = \"s3\",\n    connection_options = {\"paths\":[s3_path]},\n    format = \"json\"\n)",
			"metadata": {
				"trusted": true,
				"tags": []
			},
			"execution_count": 3,
			"outputs": [
				{
					"name": "stdout",
					"text": "\n",
					"output_type": "stream"
				}
			]
		},
		{
			"cell_type": "code",
			"source": "source_df = source_dyf.toDF()\ndf = source_df\ndf.withColumn(\"items\",explode(\"items\")).show(5)",
			"metadata": {
				"trusted": true,
				"tags": []
			},
			"execution_count": 4,
			"outputs": [
				{
					"name": "stdout",
					"text": "+--------------------+--------------------+-----+----+------+--------+-----+\n|                href|               items|limit|next|offset|previous|total|\n+--------------------+--------------------+-----+----+------+--------+-----+\n|https://api.spoti...|{2024-08-22T09:30...|  100|null|     0|    null|   50|\n|https://api.spoti...|{2024-08-22T09:30...|  100|null|     0|    null|   50|\n|https://api.spoti...|{2024-08-22T09:30...|  100|null|     0|    null|   50|\n|https://api.spoti...|{2024-08-22T09:30...|  100|null|     0|    null|   50|\n|https://api.spoti...|{2024-08-22T09:30...|  100|null|     0|    null|   50|\n+--------------------+--------------------+-----+----+------+--------+-----+\nonly showing top 5 rows\n\n/opt/amazon/spark/python/lib/pyspark.zip/pyspark/sql/dataframe.py:127: UserWarning: DataFrame constructor is internal. Do not directly use it.\n",
					"output_type": "stream"
				}
			]
		},
		{
			"cell_type": "code",
			"source": "def df_album(df):\n    return df.withColumn(\"items\",explode(\"items\")).select(\n    (col(\"items.track.album.id\").alias(\"album_id\")),\n    (col(\"items.track.album.name\").alias(\"album_name\")),\n    (col(\"items.track.album.external_urls.spotify\").alias(\"external_urls\")),\n    (col(\"items.track.album.release_date\").alias(\"release_dates\")),\n    (col(\"items.track.album.total_tracks\").alias(\"total_tracks\"))).drop_duplicates(['album_id'])\ndef df_artist(df):\n    df_exploded = df.withColumn(\"items\",explode(\"items\"))\n    df_artist_exploded = df_exploded.withColumn(\"items\", explode(\"items.track.artists\"))\n    return df_artist_exploded.select(\n    col(\"items.id\").alias(\"artist_id\"),\n    col(\"items.name\").alias(\"artist_name\"),\n    col(\"items.external_urls.spotify\").alias(\"external_urls\")).drop_duplicates(['artist_id'])\ndef df_songs(df):\n    return df.withColumn(\"items\",explode(\"items\")).select(\n    col(\"items.track.id\").alias(\"song_id\"),\n    col(\"items.track.name\").alias(\"song_name\"),\n    round(col(\"items.track.duration_ms\")/60000,2).alias(\"song_duration\"),\n    col(\"items.track.popularity\").alias(\"popularity\")).drop_duplicates(['song_id'])",
			"metadata": {
				"trusted": true,
				"tags": []
			},
			"execution_count": 5,
			"outputs": [
				{
					"name": "stdout",
					"text": "\n",
					"output_type": "stream"
				}
			]
		},
		{
			"cell_type": "code",
			"source": "album_df = df_album(df)\nalbum_df.show(5)",
			"metadata": {
				"trusted": true,
				"tags": []
			},
			"execution_count": 6,
			"outputs": [
				{
					"name": "stdout",
					"text": "+--------------------+--------------------+--------------------+-------------+------------+\n|            album_id|          album_name|       external_urls|release_dates|total_tracks|\n+--------------------+--------------------+--------------------+-------------+------------+\n|013jUXOfDFXnDMBet...|          Lost;Found|https://open.spot...|   2024-05-25|          14|\n|0LcyzKKw3RjFKL6yg...|         Ek Tha Raja|https://open.spot...|   2024-03-18|          16|\n|0a183xiCHiC1GQd8o...|              ANIMAL|https://open.spot...|   2023-11-24|           8|\n|0cJXodCZCl2EWRNcw...|Tainu Khabar Nahi...|https://open.spot...|   2024-05-31|           1|\n|0kZKLq2WZQWvXvbxv...|Janiye (from the ...|https://open.spot...|   2023-03-17|           1|\n+--------------------+--------------------+--------------------+-------------+------------+\nonly showing top 5 rows\n",
					"output_type": "stream"
				}
			]
		},
		{
			"cell_type": "code",
			"source": "artist_df = df_artist(df)\nartist_df.show(5)",
			"metadata": {
				"trusted": true,
				"tags": []
			},
			"execution_count": 7,
			"outputs": [
				{
					"name": "stdout",
					"text": "+--------------------+---------------+--------------------+\n|           artist_id|    artist_name|       external_urls|\n+--------------------+---------------+--------------------+\n|00sCATpEvwH48ays7...|  Jonita Gandhi|https://open.spot...|\n|05dG9pMLRWenxzvSm...|       MixSingh|https://open.spot...|\n|05etL4pzWd6TSv1x5...|Faheem Abdullah|https://open.spot...|\n|09UmIX92EUH9hAK4b...|        Mithoon|https://open.spot...|\n|0NErdIJtuKBjtxKml...|    Divya Kumar|https://open.spot...|\n+--------------------+---------------+--------------------+\nonly showing top 5 rows\n",
					"output_type": "stream"
				}
			]
		},
		{
			"cell_type": "code",
			"source": "songs_df = df_songs(df)\nsongs_df.show(5)",
			"metadata": {
				"trusted": true,
				"tags": []
			},
			"execution_count": 8,
			"outputs": [
				{
					"name": "stdout",
					"text": "+--------------------+--------------------+-------------+----------+\n|             song_id|           song_name|song_duration|popularity|\n+--------------------+--------------------+-------------+----------+\n|0645eBDehHcqfiF15...|Janiye (from the ...|         3.72|        77|\n|0M0ANKNzmM4Odd7FN...|Akhiyaan Gulaab (...|         2.85|        77|\n|0MTdYgTZ25sLCO6kV...|Aasa Kooda - From...|         3.59|        81|\n|0OA00aPt3BV10qeMI...|           Big Dawgs|         3.18|        91|\n|0TL0LFcwIBF5eX7ar...|                Husn|         3.63|        78|\n+--------------------+--------------------+-------------+----------+\nonly showing top 5 rows\n",
					"output_type": "stream"
				}
			]
		},
		{
			"cell_type": "code",
			"source": "def write_to_s3(df, path_suffix, format_type = \"csv\"):\n    dynamic_frame = DynamicFrame.fromDF(df, glueContext, \"dynamic_frame\")\n    glueContext.write_dynamic_frame.from_options(\n    frame = dynamic_frame,\n    connection_type = \"s3\",\n    connection_options = {\"path\": f\"s3://spotify-bucket-etl-ashutosh/transformed-data/{path_suffix}/\"},\n    format = format_type\n    )",
			"metadata": {
				"trusted": true,
				"tags": []
			},
			"execution_count": 9,
			"outputs": [
				{
					"name": "stdout",
					"text": "\n",
					"output_type": "stream"
				}
			]
		},
		{
			"cell_type": "code",
			"source": "write_to_s3(album_df, \"album_data/transformed_album_{}\".format(datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")),\"csv\")\nwrite_to_s3(artist_df, \"artist_data/transformed_artist_{}\".format(datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")),\"csv\")\nwrite_to_s3(songs_df, \"songs_data/transformed_songs_{}\".format(datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")),\"csv\")\n",
			"metadata": {
				"trusted": true,
				"tags": []
			},
			"execution_count": 10,
			"outputs": [
				{
					"name": "stdout",
					"text": "\n",
					"output_type": "stream"
				}
			]
		},
		{
			"cell_type": "code",
			"source": "def list_s3_objects(buckets,prefix):\n    s3_client = boto3.client('s3')\n    response = s3_client.list_objects_v2(Bucket=buckets, Prefix=prefix)\n    keys = [content['Key'] for content in response.get('Contents', []) if content['Key'].endswith('.json')]\n    return keys",
			"metadata": {
				"trusted": true,
				"tags": []
			},
			"execution_count": 1,
			"outputs": [
				{
					"name": "stdout",
					"text": "Welcome to the Glue Interactive Sessions Kernel\nFor more information on available magic commands, please type %help in any new cell.\n\nPlease view our Getting Started page to access the most up-to-date information on the Interactive Sessions kernel: https://docs.aws.amazon.com/glue/latest/dg/interactive-sessions.html\nInstalled kernel version: 1.0.5 \nTrying to create a Glue session for the kernel.\nSession Type: glueetl\nSession ID: c7285399-dcf0-4d45-bf4b-693b5d7895ac\nApplying the following default arguments:\n--glue_kernel_version 1.0.5\n--enable-glue-datacatalog true\nWaiting for session c7285399-dcf0-4d45-bf4b-693b5d7895ac to get into ready status...\nSession c7285399-dcf0-4d45-bf4b-693b5d7895ac has been created.\n\n",
					"output_type": "stream"
				}
			]
		},
		{
			"cell_type": "code",
			"source": "bucket_name = \"spotify-bucket-etl-ashutosh\"\nprefix = \"raw-data/to-be-processed-data/\"\nspotify_keys = list_s3_objects(bucket_name,prefix)",
			"metadata": {
				"trusted": true,
				"tags": []
			},
			"execution_count": 21,
			"outputs": [
				{
					"name": "stdout",
					"text": "\n",
					"output_type": "stream"
				}
			]
		},
		{
			"cell_type": "code",
			"source": "def move_and_delete_files(spotify_keys,bucket):\n    s3_resource = boto3.resource('s3')\n    for key in spotify_keys:\n        copy_source = {\n            'Bucket': bucket,\n            'Key': key\n        }\n        new_key = \"raw-data/processed-data/\" + key.split(\"/\")[-1]\n        s3_resource.meta.client.copy(copy_source, bucket, new_key)\n        s3_resource.Object(bucket, key).delete()",
			"metadata": {
				"trusted": true,
				"tags": []
			},
			"execution_count": 22,
			"outputs": [
				{
					"name": "stdout",
					"text": "\n",
					"output_type": "stream"
				}
			]
		},
		{
			"cell_type": "code",
			"source": "move_and_delete_files(spotify_keys,bucket_name)",
			"metadata": {
				"trusted": true,
				"tags": []
			},
			"execution_count": 23,
			"outputs": [
				{
					"name": "stdout",
					"text": "\n",
					"output_type": "stream"
				}
			]
		},
		{
			"cell_type": "code",
			"source": "job.commit()",
			"metadata": {
				"trusted": true,
				"tags": []
			},
			"execution_count": 18,
			"outputs": [
				{
					"name": "stdout",
					"text": "\n",
					"output_type": "stream"
				}
			]
		},
		{
			"cell_type": "code",
			"source": "",
			"metadata": {},
			"execution_count": null,
			"outputs": []
		}
	]
}